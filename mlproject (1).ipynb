{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "df = pd.read_csv('DATA-FINAL.csv')\n",
    "if os.path.isfile('Mydata1.csv'):\n",
    "    print(\"not create again\");\n",
    "else:\n",
    "    lst =  [['Termid','RegdNo','Course','Grade','CA_100','MTT_50','ETT_100','ETP_100','Course_Att','MHRDName','CA_1','CA_2','CA_3','CA_4','Height','Weight','ScholarType','Direction','Gender','Medium','CourseType','ProgramType']]\n",
    "    d= pd.DataFrame(lst)\n",
    "    for i in range(df.Termid.count()):\n",
    "        if i == 0:\n",
    "            d.to_csv('Mydata1.csv',mode='a',header=False) \n",
    "        if df.MHRDName[i] == \"Bachelor of Science (Honours) (Agriculture )\" :\n",
    "            df.iloc[i:i+1,:].to_csv('Mydata1.csv',mode='a',header=False)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0         Termid        RegdNo      CA_100     MTT_50  \\\n",
      "count    107.000000     107.000000  1.070000e+02  107.000000  58.000000   \n",
      "mean   31830.607477  244360.224299  8.254243e+06   74.196262  29.741379   \n",
      "std    17695.707179   58819.276455  3.893697e+06   14.574104  10.051726   \n",
      "min     2149.000000  118192.000000  1.663776e+06   32.000000   8.000000   \n",
      "25%    15532.500000  218192.000000  4.689776e+06   67.000000  23.000000   \n",
      "50%    33099.000000  218192.000000  8.560776e+06   75.000000  30.000000   \n",
      "75%    45215.500000  318192.000000  1.126078e+07   86.500000  37.750000   \n",
      "max    63653.000000  318192.000000  1.509278e+07   97.000000  47.000000   \n",
      "\n",
      "         ETT_100    ETP_100  Course_Att        CA_1        CA_2        CA_3  \\\n",
      "count  59.000000  48.000000   95.000000  107.000000  107.000000  107.000000   \n",
      "mean   65.610169  73.416667   92.389474   38.570093   18.663551    8.728972   \n",
      "std    24.968267  16.343173    8.324911   22.720663   18.546700   12.601715   \n",
      "min     0.000000   0.000000   62.000000    1.000000    0.000000    0.000000   \n",
      "25%    61.000000  66.750000   88.000000   20.500000    5.500000    1.000000   \n",
      "50%    72.000000  76.500000   93.000000   36.000000   12.000000    3.000000   \n",
      "75%    82.500000  83.250000  100.000000   53.500000   28.000000   11.500000   \n",
      "max    96.000000  96.000000  100.000000   94.000000   75.000000   73.000000   \n",
      "\n",
      "             CA_4      Height      Weight  \n",
      "count  107.000000  107.000000  107.000000  \n",
      "mean     8.233645  165.719626   67.971963  \n",
      "std     10.063552   10.633513   14.849216  \n",
      "min      0.000000  151.000000   41.000000  \n",
      "25%      1.000000  155.000000   55.000000  \n",
      "50%      5.000000  168.000000   68.000000  \n",
      "75%     10.500000  173.000000   80.000000  \n",
      "max     43.000000  184.000000   95.000000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"Mydata.csv\")       \n",
    "df.head() #it will print upto 5 rows and column.\n",
    "\n",
    "#Size of dataset\n",
    "df.shape\n",
    "\n",
    "#To check if there is any null value or not\n",
    "df.isnull()\n",
    "\n",
    "#total number of null value\n",
    "df.isnull().sum()\n",
    "\n",
    "#To drop the column which is having null values so that our model will predict good accuracy\n",
    "\n",
    "print(df.describe())\n",
    "df.fillna(df.max(), inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding outliers\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27ace0a6da0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['MTT_50'].plot.box()\n",
    "df['ETT_100'].plot.box()\n",
    "df['ETP_100'].plot.box()\n",
    "df['CA_1'].plot.box()\n",
    "df['CA_2'].plot.box()\n",
    "df['CA_3'].plot.box()\n",
    "df['CA_4'].plot.box()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              107\n",
       "Termid           3\n",
       "RegdNo          20\n",
       "Course          21\n",
       "Grade            8\n",
       "CA_100          43\n",
       "MTT_50          27\n",
       "ETT_100         31\n",
       "ETP_100         30\n",
       "Course_Att      26\n",
       "MHRDName         1\n",
       "CA_1            67\n",
       "CA_2            44\n",
       "CA_3            31\n",
       "CA_4            31\n",
       "Height          13\n",
       "Weight          19\n",
       "ScholarType      2\n",
       "Direction        4\n",
       "Gender           2\n",
       "Medium           3\n",
       "CourseType       1\n",
       "ProgramType      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Statistical Description of datasets\n",
    "df.describe()\n",
    "\n",
    "#It shows all columns\n",
    "df.columns\n",
    "\n",
    "#It is used for finding unique values\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     21\n",
       "1.0     13\n",
       "2.0      9\n",
       "6.0      7\n",
       "7.0      7\n",
       "3.0      6\n",
       "5.0      5\n",
       "9.0      4\n",
       "10.0     4\n",
       "21.0     3\n",
       "4.0      3\n",
       "24.0     2\n",
       "39.0     2\n",
       "15.0     2\n",
       "22.0     2\n",
       "12.0     2\n",
       "19.0     1\n",
       "25.0     1\n",
       "28.0     1\n",
       "16.0     1\n",
       "26.0     1\n",
       "33.0     1\n",
       "20.0     1\n",
       "8.0      1\n",
       "43.0     1\n",
       "31.0     1\n",
       "13.0     1\n",
       "11.0     1\n",
       "18.0     1\n",
       "14.0     1\n",
       "36.0     1\n",
       "Name: CA_4, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It is used to how many times a specific number is present in our dataset\n",
    "freq_df=df['CA_100'].value_counts()\n",
    "freq_df\n",
    "freq_df=df['CA_1'].value_counts()\n",
    "freq_df\n",
    "freq_df=df['CA_2'].value_counts()\n",
    "freq_df\n",
    "freq_df=df['CA_3'].value_counts()\n",
    "freq_df\n",
    "freq_df=df['CA_4'].value_counts()\n",
    "freq_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27ace1942b0>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#It is used to plot graph and histogram on jupyter notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df['CA_100'].plot.hist()\n",
    "df['MTT_50'].plot.hist()\n",
    "df['ETT_100'].plot.hist()\n",
    "df['ETP_100'].plot.hist()\n",
    "df['CA_1'].plot.hist()\n",
    "df['CA_2'].plot.hist()\n",
    "df['CA_3'].plot.hist()\n",
    "df['CA_4'].plot.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Termid</th>\n",
       "      <th>RegdNo</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048282</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.308832</td>\n",
       "      <td>0.212929</td>\n",
       "      <td>0.243551</td>\n",
       "      <td>0.038111</td>\n",
       "      <td>0.265513</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.122870</td>\n",
       "      <td>0.078228</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.050586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Termid</th>\n",
       "      <td>-0.048282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.049468</td>\n",
       "      <td>0.072088</td>\n",
       "      <td>0.312045</td>\n",
       "      <td>0.285216</td>\n",
       "      <td>-0.350234</td>\n",
       "      <td>0.440344</td>\n",
       "      <td>-0.215278</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>0.261664</td>\n",
       "      <td>0.284419</td>\n",
       "      <td>-0.182734</td>\n",
       "      <td>0.140183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegdNo</th>\n",
       "      <td>0.999917</td>\n",
       "      <td>-0.049468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306536</td>\n",
       "      <td>0.210871</td>\n",
       "      <td>0.242083</td>\n",
       "      <td>0.038034</td>\n",
       "      <td>0.263993</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.121393</td>\n",
       "      <td>0.077509</td>\n",
       "      <td>0.338641</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_100</th>\n",
       "      <td>0.308832</td>\n",
       "      <td>0.072088</td>\n",
       "      <td>0.306536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.530010</td>\n",
       "      <td>0.546557</td>\n",
       "      <td>-0.126853</td>\n",
       "      <td>0.361115</td>\n",
       "      <td>0.293703</td>\n",
       "      <td>0.237996</td>\n",
       "      <td>0.216649</td>\n",
       "      <td>0.075199</td>\n",
       "      <td>0.187426</td>\n",
       "      <td>0.153078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTT_50</th>\n",
       "      <td>0.212929</td>\n",
       "      <td>0.312045</td>\n",
       "      <td>0.210871</td>\n",
       "      <td>0.530010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693614</td>\n",
       "      <td>-0.537360</td>\n",
       "      <td>0.431059</td>\n",
       "      <td>-0.101765</td>\n",
       "      <td>0.222933</td>\n",
       "      <td>0.324379</td>\n",
       "      <td>0.180274</td>\n",
       "      <td>0.122446</td>\n",
       "      <td>0.246596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETT_100</th>\n",
       "      <td>0.243551</td>\n",
       "      <td>0.285216</td>\n",
       "      <td>0.242083</td>\n",
       "      <td>0.546557</td>\n",
       "      <td>0.693614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.457153</td>\n",
       "      <td>0.567731</td>\n",
       "      <td>-0.060411</td>\n",
       "      <td>0.215239</td>\n",
       "      <td>0.238360</td>\n",
       "      <td>0.232764</td>\n",
       "      <td>0.167056</td>\n",
       "      <td>0.104893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETP_100</th>\n",
       "      <td>0.038111</td>\n",
       "      <td>-0.350234</td>\n",
       "      <td>0.038034</td>\n",
       "      <td>-0.126853</td>\n",
       "      <td>-0.537360</td>\n",
       "      <td>-0.457153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.226005</td>\n",
       "      <td>0.032391</td>\n",
       "      <td>0.036024</td>\n",
       "      <td>-0.211915</td>\n",
       "      <td>-0.057867</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>-0.151457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Course_Att</th>\n",
       "      <td>0.265513</td>\n",
       "      <td>0.440344</td>\n",
       "      <td>0.263993</td>\n",
       "      <td>0.361115</td>\n",
       "      <td>0.431059</td>\n",
       "      <td>0.567731</td>\n",
       "      <td>-0.226005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.045347</td>\n",
       "      <td>0.157002</td>\n",
       "      <td>0.143479</td>\n",
       "      <td>0.156337</td>\n",
       "      <td>0.167790</td>\n",
       "      <td>0.016244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_1</th>\n",
       "      <td>0.081400</td>\n",
       "      <td>-0.215278</td>\n",
       "      <td>0.081488</td>\n",
       "      <td>0.293703</td>\n",
       "      <td>-0.101765</td>\n",
       "      <td>-0.060411</td>\n",
       "      <td>0.032391</td>\n",
       "      <td>-0.045347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.545103</td>\n",
       "      <td>-0.387332</td>\n",
       "      <td>-0.342751</td>\n",
       "      <td>0.089267</td>\n",
       "      <td>0.012575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_2</th>\n",
       "      <td>0.017030</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.237996</td>\n",
       "      <td>0.222933</td>\n",
       "      <td>0.215239</td>\n",
       "      <td>0.036024</td>\n",
       "      <td>0.157002</td>\n",
       "      <td>-0.545103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098802</td>\n",
       "      <td>-0.143880</td>\n",
       "      <td>0.057207</td>\n",
       "      <td>0.104683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3</th>\n",
       "      <td>0.122870</td>\n",
       "      <td>0.261664</td>\n",
       "      <td>0.121393</td>\n",
       "      <td>0.216649</td>\n",
       "      <td>0.324379</td>\n",
       "      <td>0.238360</td>\n",
       "      <td>-0.211915</td>\n",
       "      <td>0.143479</td>\n",
       "      <td>-0.387332</td>\n",
       "      <td>-0.098802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118114</td>\n",
       "      <td>0.067929</td>\n",
       "      <td>0.040493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_4</th>\n",
       "      <td>0.078228</td>\n",
       "      <td>0.284419</td>\n",
       "      <td>0.077509</td>\n",
       "      <td>0.075199</td>\n",
       "      <td>0.180274</td>\n",
       "      <td>0.232764</td>\n",
       "      <td>-0.057867</td>\n",
       "      <td>0.156337</td>\n",
       "      <td>-0.342751</td>\n",
       "      <td>-0.143880</td>\n",
       "      <td>0.118114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.120601</td>\n",
       "      <td>-0.050334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>0.343200</td>\n",
       "      <td>-0.182734</td>\n",
       "      <td>0.338641</td>\n",
       "      <td>0.187426</td>\n",
       "      <td>0.122446</td>\n",
       "      <td>0.167056</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>0.167790</td>\n",
       "      <td>0.089267</td>\n",
       "      <td>0.057207</td>\n",
       "      <td>0.067929</td>\n",
       "      <td>-0.120601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>0.050586</td>\n",
       "      <td>0.140183</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.153078</td>\n",
       "      <td>0.246596</td>\n",
       "      <td>0.104893</td>\n",
       "      <td>-0.151457</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.012575</td>\n",
       "      <td>0.104683</td>\n",
       "      <td>0.040493</td>\n",
       "      <td>-0.050334</td>\n",
       "      <td>0.329393</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0    Termid    RegdNo    CA_100    MTT_50   ETT_100  \\\n",
       "0           1.000000 -0.048282  0.999917  0.308832  0.212929  0.243551   \n",
       "Termid     -0.048282  1.000000 -0.049468  0.072088  0.312045  0.285216   \n",
       "RegdNo      0.999917 -0.049468  1.000000  0.306536  0.210871  0.242083   \n",
       "CA_100      0.308832  0.072088  0.306536  1.000000  0.530010  0.546557   \n",
       "MTT_50      0.212929  0.312045  0.210871  0.530010  1.000000  0.693614   \n",
       "ETT_100     0.243551  0.285216  0.242083  0.546557  0.693614  1.000000   \n",
       "ETP_100     0.038111 -0.350234  0.038034 -0.126853 -0.537360 -0.457153   \n",
       "Course_Att  0.265513  0.440344  0.263993  0.361115  0.431059  0.567731   \n",
       "CA_1        0.081400 -0.215278  0.081488  0.293703 -0.101765 -0.060411   \n",
       "CA_2        0.017030 -0.011743  0.016512  0.237996  0.222933  0.215239   \n",
       "CA_3        0.122870  0.261664  0.121393  0.216649  0.324379  0.238360   \n",
       "CA_4        0.078228  0.284419  0.077509  0.075199  0.180274  0.232764   \n",
       "Height      0.343200 -0.182734  0.338641  0.187426  0.122446  0.167056   \n",
       "Weight      0.050586  0.140183  0.046512  0.153078  0.246596  0.104893   \n",
       "\n",
       "             ETP_100  Course_Att      CA_1      CA_2      CA_3      CA_4  \\\n",
       "0           0.038111    0.265513  0.081400  0.017030  0.122870  0.078228   \n",
       "Termid     -0.350234    0.440344 -0.215278 -0.011743  0.261664  0.284419   \n",
       "RegdNo      0.038034    0.263993  0.081488  0.016512  0.121393  0.077509   \n",
       "CA_100     -0.126853    0.361115  0.293703  0.237996  0.216649  0.075199   \n",
       "MTT_50     -0.537360    0.431059 -0.101765  0.222933  0.324379  0.180274   \n",
       "ETT_100    -0.457153    0.567731 -0.060411  0.215239  0.238360  0.232764   \n",
       "ETP_100     1.000000   -0.226005  0.032391  0.036024 -0.211915 -0.057867   \n",
       "Course_Att -0.226005    1.000000 -0.045347  0.157002  0.143479  0.156337   \n",
       "CA_1        0.032391   -0.045347  1.000000 -0.545103 -0.387332 -0.342751   \n",
       "CA_2        0.036024    0.157002 -0.545103  1.000000 -0.098802 -0.143880   \n",
       "CA_3       -0.211915    0.143479 -0.387332 -0.098802  1.000000  0.118114   \n",
       "CA_4       -0.057867    0.156337 -0.342751 -0.143880  0.118114  1.000000   \n",
       "Height      0.096775    0.167790  0.089267  0.057207  0.067929 -0.120601   \n",
       "Weight     -0.151457    0.016244  0.012575  0.104683  0.040493 -0.050334   \n",
       "\n",
       "              Height    Weight  \n",
       "0           0.343200  0.050586  \n",
       "Termid     -0.182734  0.140183  \n",
       "RegdNo      0.338641  0.046512  \n",
       "CA_100      0.187426  0.153078  \n",
       "MTT_50      0.122446  0.246596  \n",
       "ETT_100     0.167056  0.104893  \n",
       "ETP_100     0.096775 -0.151457  \n",
       "Course_Att  0.167790  0.016244  \n",
       "CA_1        0.089267  0.012575  \n",
       "CA_2        0.057207  0.104683  \n",
       "CA_3        0.067929  0.040493  \n",
       "CA_4       -0.120601 -0.050334  \n",
       "Height      1.000000  0.329393  \n",
       "Weight      0.329393  1.000000  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To find the relation betweeen two attributes\n",
    "df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ETT_100  CA_1  CA_2  CA_3  Course_Att\n",
      "0       96.0  10.0  31.0   5.0       100.0\n",
      "1       96.0  20.0  15.0  33.0       100.0\n",
      "2       76.0  14.0  42.0  11.0       100.0\n",
      "3       96.0  16.0  20.0   6.0       100.0\n",
      "4       96.0  51.0   6.0  12.0       100.0\n",
      "5       92.0  35.0  26.0   8.0       100.0\n",
      "6       66.0  68.0   2.0   0.0        78.0\n",
      "7       75.0  64.0  10.0   1.0        88.0\n",
      "8       88.0  70.0   0.0   1.0        93.0\n",
      "9       96.0  31.0  12.0  21.0        92.0\n",
      "10      96.0  17.0  75.0   0.0       100.0\n",
      "11      82.0  18.0  44.0   2.0        97.0\n",
      "12      76.0  38.0  29.0   2.0        98.0\n",
      "13      63.0  52.0  14.0   3.0        85.0\n",
      "14      96.0  17.0  31.0   0.0        98.0\n",
      "15      58.0  49.0   7.0   3.0        75.0\n",
      "16       0.0  13.0  24.0   2.0        69.0\n",
      "17       0.0  43.0   1.0   0.0        85.0\n",
      "18      96.0  74.0   1.0   3.0        85.0\n",
      "19      96.0  68.0   4.0   0.0        86.0\n",
      "20       0.0  52.0   7.0   0.0        79.0\n",
      "21       0.0  59.0  11.0   0.0        81.0\n",
      "22       0.0  48.0   3.0   3.0        68.0\n",
      "23      96.0  27.0  13.0   5.0        62.0\n",
      "24      96.0  41.0  20.0  11.0       100.0\n",
      "25      96.0  10.0   3.0  21.0       100.0\n",
      "26      66.0  55.0   7.0   0.0       100.0\n",
      "27      96.0  31.0  31.0  25.0       100.0\n",
      "28      96.0  56.0   9.0   0.0       100.0\n",
      "29      90.0  15.0  34.0  34.0       100.0\n",
      "..       ...   ...   ...   ...         ...\n",
      "77      76.0  35.0  35.0   1.0       100.0\n",
      "78      38.0  23.0  40.0   3.0        82.0\n",
      "79      78.0  37.0  14.0   0.0        89.0\n",
      "80      96.0   1.0   7.0  73.0        96.0\n",
      "81      96.0  73.0   0.0   9.0        98.0\n",
      "82      70.0   5.0   1.0   3.0        87.0\n",
      "83      72.0  69.0   9.0   0.0        84.0\n",
      "84      75.0  36.0  16.0  12.0        70.0\n",
      "85      96.0  19.0  59.0   1.0        93.0\n",
      "86      59.0  41.0   5.0  14.0        79.0\n",
      "87      96.0  19.0   6.0  27.0        91.0\n",
      "88      96.0  28.0  15.0  36.0       100.0\n",
      "89      65.0   3.0  10.0  38.0        87.0\n",
      "90      96.0  12.0  66.0   2.0        93.0\n",
      "91      86.0  76.0   8.0   3.0        93.0\n",
      "92      66.0  91.0   3.0   0.0        97.0\n",
      "93      96.0  25.0  47.0   1.0        87.0\n",
      "94      62.0  26.0  31.0  13.0        88.0\n",
      "95      96.0  56.0  21.0   7.0       100.0\n",
      "96      93.0  94.0   0.0   1.0        91.0\n",
      "97      65.0  53.0   8.0  10.0        91.0\n",
      "98      96.0  49.0   0.0  14.0       100.0\n",
      "99      96.0  87.0   2.0   0.0       100.0\n",
      "100     88.0  38.0   7.0   1.0       100.0\n",
      "101     96.0  29.0   4.0  25.0       100.0\n",
      "102     96.0  40.0  20.0  15.0       100.0\n",
      "103     79.0  60.0   2.0   8.0       100.0\n",
      "104     96.0  32.0  12.0  15.0       100.0\n",
      "105     96.0  33.0   8.0  43.0       100.0\n",
      "106     90.0  18.0  66.0   6.0       100.0\n",
      "\n",
      "[107 rows x 5 columns]\n",
      "[74. 67. 96. 64. 72. 96. 96. 96. 96. 80. 80. 96. 96. 96. 82. 96. 96. 96.\n",
      "  0. 76. 96. 96. 96. 81. 69. 51. 96. 88. 59. 96. 96. 96. 96. 84. 80. 96.\n",
      " 96. 96. 89. 96. 96. 96. 66. 81. 96. 96. 96. 91. 76. 77. 96. 96. 96. 96.\n",
      " 78. 78. 96. 96. 96. 86. 59. 76. 96. 96. 64. 96. 45. 54. 96. 96. 96. 83.\n",
      " 71. 96. 96. 96. 86. 96. 96. 96. 75. 74. 96. 96. 96. 89. 96. 43. 59. 96.\n",
      " 89. 96. 96. 88. 96. 85. 96. 96. 62. 83. 96. 81. 72. 96. 91. 70. 96.]\n"
     ]
    }
   ],
   "source": [
    "#Here we are dividing our data into two parts one is for training and other is for testing\n",
    "X=df[['ETT_100','CA_1','CA_2','CA_3','Course_Att']]                           #Training part\n",
    "print(X)\n",
    "\n",
    "y=df['ETP_100'].values   #Testing part\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42424242424242425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "from sklearn.svm import SVC  \n",
    "svc=SVC(kernel='poly')\n",
    "svc.fit(X_train,y_train)     #fitting the model\n",
    "y_predict=svc.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score      #Importing accuracy_score model for testing\n",
    "p=accuracy_score(y_predict,y_test)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "#using Rbf kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='rbf')                                      #here we used rbf kernel\n",
    "svc.fit(X_train,y_train)\n",
    "y_predict=svc.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score      #Importing accuracy_score model for testing\n",
    "p=accuracy_score(y_predict,y_test)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Decision Tree Algorithm\n",
    "from sklearn.preprocessing import StandardScaler                 \n",
    "sc=StandardScaler()                  #Importing StandardScaler classifier\n",
    "X=sc.fit_transform(X)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X=sc.fit_transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.5)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "y_pred=dt.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "m=accuracy_score(y_pred,y_test)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.704119   -1.26336725  0.66828616 -0.29730241  0.82765705]\n",
      " [ 0.704119   -0.82116805 -0.19846074  1.93507361  0.82765705]\n",
      " [-0.13626843 -1.08648757  1.26417465  0.18106388  0.82765705]\n",
      " [ 0.704119   -0.99804773  0.07239767 -0.2175747   0.82765705]\n",
      " [ 0.704119    0.54964948 -0.68600587  0.26079159  0.82765705]\n",
      " [ 0.53604151 -0.15786925  0.39742775 -0.05811927  0.82765705]\n",
      " [-0.55646214  1.30138812 -0.90269259 -0.69594099 -1.86709356]\n",
      " [-0.1782878   1.12450844 -0.46931914 -0.61621328 -0.64220692]\n",
      " [ 0.36796403  1.38982796 -1.01103596 -0.61621328 -0.0297636 ]\n",
      " [ 0.704119   -0.33474893 -0.36097578  0.97834103 -0.15225226]\n",
      " [ 0.704119   -0.95382781  3.05184013 -0.69594099  0.82765705]\n",
      " [ 0.1158478  -0.90960789  1.37251801 -0.53648556  0.46019105]\n",
      " [-0.13626843 -0.02520949  0.5599428  -0.53648556  0.58267972]\n",
      " [-0.68252025  0.5938694  -0.25263242 -0.45675785 -1.00967291]\n",
      " [ 0.704119   -0.95382781  0.66828616 -0.69594099  0.58267972]\n",
      " [-0.89261711  0.46120963 -0.63183419 -0.45675785 -2.23455955]\n",
      " [-3.32974064 -1.13070749  0.28908439 -0.53648556 -2.96949153]\n",
      " [-3.32974064  0.19589011 -0.95686427 -0.69594099 -1.00967291]\n",
      " [ 0.704119    1.56670764 -0.95686427 -0.45675785 -1.00967291]\n",
      " [ 0.704119    1.30138812 -0.79434923 -0.69594099 -0.88718425]\n",
      " [-3.32974064  0.5938694  -0.63183419 -0.69594099 -1.74460489]\n",
      " [-3.32974064  0.90340884 -0.41514746 -0.69594099 -1.49962756]\n",
      " [-3.32974064  0.41698971 -0.84852091 -0.45675785 -3.09198019]\n",
      " [ 0.704119   -0.51162861 -0.3068041  -0.29730241 -3.82691217]\n",
      " [ 0.704119    0.10745027  0.07239767  0.18106388  0.82765705]\n",
      " [ 0.704119   -1.26336725 -0.84852091  0.97834103  0.82765705]\n",
      " [-0.55646214  0.72652916 -0.63183419 -0.69594099  0.82765705]\n",
      " [ 0.704119   -0.33474893  0.66828616  1.29725189  0.82765705]\n",
      " [ 0.704119    0.77074908 -0.52349083 -0.69594099  0.82765705]\n",
      " [ 0.45200277 -1.04226765  0.8308012   2.01480133  0.82765705]\n",
      " [-1.64896579  1.12450844 -0.74017755 -0.53648556 -1.62211623]\n",
      " [-1.27079145 -1.52868677  0.45159944  0.26079159 -0.64220692]\n",
      " [-0.72453962 -1.26336725  0.88497288 -0.13784698 -0.76469558]\n",
      " [ 0.704119   -0.77694813  0.72245784 -0.45675785 -0.15225226]\n",
      " [ 0.704119   -1.35180709  1.6975481   1.61616275 -0.0297636 ]\n",
      " [-0.13626843 -1.13070749 -0.57766251  0.10133616 -0.51971826]\n",
      " [ 0.28392528 -0.55584853 -1.01103596  1.37697961 -0.27474093]\n",
      " [ 0.4099834  -0.46740869  0.77662952 -0.61621328 -1.00967291]\n",
      " [ 0.704119   -0.11364933 -0.41514746 -0.45675785 -0.0297636 ]\n",
      " [-1.10271397 -0.42318877  0.34325607  0.97834103 -0.27474093]\n",
      " [-1.81704328  0.28432995 -0.95686427 -0.69594099  0.46019105]\n",
      " [-0.59848151 -0.29052901 -0.25263242 -0.69594099  0.21521373]\n",
      " [ 0.704119    0.32854987  0.01822599  0.02160845 -0.76469558]\n",
      " [ 0.704119    1.0360686  -0.14428906 -0.53648556 -0.0297636 ]\n",
      " [-1.69098516 -0.33474893 -1.01103596 -0.61621328  0.46019105]\n",
      " [-0.1782878   1.34560804 -1.01103596 -0.45675785 -0.0297636 ]\n",
      " [-1.64896579  0.814969   -0.63183419 -0.45675785 -0.0297636 ]\n",
      " [ 0.704119   -0.77694813 -0.57766251  1.77561818 -0.0297636 ]\n",
      " [ 0.704119    0.68230924  0.23491271 -0.53648556  0.82765705]\n",
      " [ 0.704119   -0.37896885  2.18509323 -0.37703013  0.82765705]\n",
      " [ 0.704119    2.23000644 -1.01103596 -0.69594099  0.82765705]\n",
      " [-0.68252025  1.38982796 -0.95686427 -0.61621328 -0.51971826]\n",
      " [-0.38838466 -1.48446685  1.80589146 -0.69594099 -0.27474093]\n",
      " [-0.43040403  1.16872836 -1.01103596 -0.53648556 -0.27474093]\n",
      " [ 0.704119    0.63808932 -0.68600587  1.13779646  0.09272506]\n",
      " [ 0.704119    0.28432995  0.88497288 -0.69594099  0.82765705]\n",
      " [-0.80857837  0.01901043 -0.63183419 -0.69594099 -0.0297636 ]\n",
      " [-0.13626843 -0.42318877  0.28908439  1.13779646 -0.51971826]\n",
      " [ 0.36796403 -0.60006845  1.53503306 -0.69594099 -0.27474093]\n",
      " [ 0.704119    0.63808932 -0.19846074 -0.29730241 -0.0297636 ]\n",
      " [ 0.704119   -1.30758717  0.23491271  0.10133616  0.82765705]\n",
      " [ 0.704119   -1.44024693  0.23491271  3.29044477  0.82765705]\n",
      " [ 0.03180906 -1.66134653 -0.03594569 -0.53648556  0.58267972]\n",
      " [ 0.704119   -0.46740869  2.564295   -0.69594099  0.82765705]\n",
      " [ 0.704119    0.15167019 -0.90269259 -0.69594099  0.82765705]\n",
      " [ 0.4099834  -0.11364933 -0.52349083  1.21752417  0.82765705]\n",
      " [ 0.704119    0.5938694  -0.25263242 -0.69594099  0.82765705]\n",
      " [ 0.704119   -1.08648757  1.91423483 -0.61621328  0.82765705]\n",
      " [ 0.4099834   0.814969   -0.68600587 -0.69594099  0.82765705]\n",
      " [-0.30434591  0.54964948  0.01822599 -0.61621328  0.70516838]\n",
      " [ 0.36796403  1.920467   -1.01103596 -0.69594099  0.82765705]\n",
      " [ 0.704119   -0.77694813  2.67263836 -0.69594099  0.58267972]\n",
      " [ 0.704119    1.61092756 -0.68600587 -0.05811927  0.82765705]\n",
      " [-0.72453962 -1.21914733 -0.36097578 -0.61621328  0.70516838]\n",
      " [ 0.1158478   0.37276979 -0.3068041   0.02160845  0.82765705]\n",
      " [ 0.15786717  0.28432995 -0.79434923 -0.05811927  0.82765705]\n",
      " [ 0.704119   -0.77694813  1.48086138 -0.37703013  0.82765705]\n",
      " [-0.13626843 -0.15786925  0.88497288 -0.61621328  0.82765705]\n",
      " [-1.73300453 -0.68850829  1.15583129 -0.45675785 -1.3771389 ]\n",
      " [-0.05222969 -0.06942941 -0.25263242 -0.69594099 -0.51971826]\n",
      " [ 0.704119   -1.66134653 -0.63183419  5.12418222  0.33770239]\n",
      " [ 0.704119    1.52248772 -1.01103596  0.02160845  0.58267972]\n",
      " [-0.38838466 -1.48446685 -0.95686427 -0.45675785 -0.76469558]\n",
      " [-0.30434591  1.34560804 -0.52349083 -0.69594099 -1.13216157]\n",
      " [-0.1782878  -0.11364933 -0.14428906  0.26079159 -2.84700286]\n",
      " [ 0.704119   -0.86538797  2.18509323 -0.61621328 -0.0297636 ]\n",
      " [-0.85059774  0.10745027 -0.74017755  0.42024702 -1.74460489]\n",
      " [ 0.704119   -0.86538797 -0.68600587  1.45670732 -0.27474093]\n",
      " [ 0.704119   -0.46740869 -0.19846074  2.17425676  0.82765705]\n",
      " [-0.59848151 -1.57290669 -0.46931914  2.33371219 -0.76469558]\n",
      " [ 0.704119   -1.17492741  2.564295   -0.53648556 -0.0297636 ]\n",
      " [ 0.28392528  1.65514748 -0.57766251 -0.45675785 -0.0297636 ]\n",
      " [-0.55646214  2.31844628 -0.84852091 -0.69594099  0.46019105]\n",
      " [ 0.704119   -0.60006845  1.53503306 -0.61621328 -0.76469558]\n",
      " [-0.72453962 -0.55584853  0.66828616  0.34051931 -0.64220692]\n",
      " [ 0.704119    0.77074908  0.12656935 -0.13784698  0.82765705]\n",
      " [ 0.57806088  2.45110604 -1.01103596 -0.61621328 -0.27474093]\n",
      " [-0.59848151  0.63808932 -0.57766251  0.10133616 -0.27474093]\n",
      " [ 0.704119    0.46120963 -1.01103596  0.42024702  0.82765705]\n",
      " [ 0.704119    2.1415666  -0.90269259 -0.69594099  0.82765705]\n",
      " [ 0.36796403 -0.02520949 -0.63183419 -0.61621328  0.82765705]\n",
      " [ 0.704119   -0.42318877 -0.79434923  1.29725189  0.82765705]\n",
      " [ 0.704119    0.06323035  0.07239767  0.49997474  0.82765705]\n",
      " [-0.01021031  0.94762876 -0.90269259 -0.05811927  0.82765705]\n",
      " [ 0.704119   -0.29052901 -0.36097578  0.49997474  0.82765705]\n",
      " [ 0.704119   -0.24630909 -0.57766251  2.73235076  0.82765705]\n",
      " [ 0.45200277 -0.90960789  2.564295   -0.2175747   0.82765705]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3939393939393939"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying random Forest Algorithm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X=sc.fit_transform(X)\n",
    "print(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "y=rf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "n=accuracy_score(y,y_test)\n",
    "n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3939393939393939"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "clf2=LogisticRegression()\n",
    "clf2.fit(x_train,y_train)\n",
    "clf3=SVC()\n",
    "clf3.fit(x_train,y_train)\n",
    "y=clf3.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "k=accuracy_score(y,y_test)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grade predicted by different classification algorithm are given below::::::::\n",
      "The accuracy predicted by SVM Using rbf Kernel is 0.42424242424242425\n",
      "The accuracy predicted using Random forest is 0.5757575757575758\n",
      "The accuracy predicted using Logistic Regression 0.5757575757575758\n",
      "The accuracy predicted using Decision Tree is 0.46296296296296297\n"
     ]
    }
   ],
   "source": [
    "#given below are the accuracy predicted by different classification technique\n",
    "print(\"The grade predicted by different classification algorithm are given below::::::::\");\n",
    "#print(\"The accuracy predicted by SVM Using Polynomial Kernel is\",x);\n",
    "print(\"The accuracy predicted by SVM Using rbf Kernel is\",p);\n",
    "print(\"The accuracy predicted using Random forest is\",n);\n",
    "print(\"The accuracy predicted using Logistic Regression\",k);\n",
    "print(\"The accuracy predicted using Decision Tree is\",m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
